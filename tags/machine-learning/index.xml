<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Nirant Kasliwal</title>
    <link>https://nirantk.com/tags/machine-learning.html</link>
    <description>Recent content in machine learning on Nirant Kasliwal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 15 Nov 2020 23:29:18 +0530</lastBuildDate><atom:link href="https://nirantk.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Read a Deep Learning Paper</title>
      <link>https://nirantk.com/writing/read-deep-learning-paper.html</link>
      <pubDate>Sun, 15 Nov 2020 23:29:18 +0530</pubDate>
      
      <guid>https://nirantk.com/writing/read-deep-learning-paper.html</guid>
      <description>Who is this for? Practitioners who are looking to level up their game in Deep Learning
Why Do We Need Instructions on How to Read a Deep Learning Paper? Quantity: There are more papers than we can humanly read even within our own niche. For instance, consider EMNLP - which is arguably the most popular Natural Language Processing conference selects more than 2K papers across a variety of topics. And NLP is just one area!</description>
    </item>
    
    <item>
      <title>Verloop NLP Interview Prep Guide</title>
      <link>https://nirantk.com/writing/verloop-ml-prep-guide.html</link>
      <pubDate>Sat, 29 Aug 2020 00:09:00 +0530</pubDate>
      
      <guid>https://nirantk.com/writing/verloop-ml-prep-guide.html</guid>
      <description>Preparation Guide I&amp;rsquo;ve been an early Machine Learning Engineer at Verloop.io for almost 1.5 years, primarily working on NLP problems and now more in an Engineering Manager-ish role.
This is the guide which I sometimes send to our candidates after they submit the Programming Challenge. If a candidate has relevant open source code sample, specially to other repositories we may choose to waive off the Programming Challenge completely.
I originally wrote this to give a chance to folks coming from non-NLP background to get a sense of the problem space a little better.</description>
    </item>
    
    <item>
      <title>Math for Machine Learning</title>
      <link>https://nirantk.com/writing/mathforai.html</link>
      <pubDate>Sun, 27 Oct 2019 23:29:18 +0530</pubDate>
      
      <guid>https://nirantk.com/writing/mathforai.html</guid>
      <description>Algebra, Topology, Differential Calculus, andi Optimization Theory For Computer Science and Machine Learning https://www.cis.upenn.edu/~jean/math-deep.pdf
Mathematics for Machine Learning: https://mml-book.github.io/book/mml-book.pdf
http://d2l.ai/chapter_appendix_math/index.html</description>
    </item>
    
    <item>
      <title>ML Model Monitoring</title>
      <link>https://nirantk.com/writing/modelmonitoring.html</link>
      <pubDate>Sat, 21 Sep 2019 00:00:18 +0530</pubDate>
      
      <guid>https://nirantk.com/writing/modelmonitoring.html</guid>
      <description>Mayank asked on Twitter:
 Some ideas/papers/tools on monitoring models in production. A use case would be say a classification task over large inputs. I want to visualise how are the predicted values or even confidence scores vary over time? (paraphrased)
 Quick Hacks pandas-profiling If you are logging confidence scores, you can begin there. The quickest hack is to visualize with pandas-profiling: https://github.com/pandas-profiling/pandas-profiling/
Rolling means Calculate rolling aggregates (e.g. mean, variance) of your confidence scores.</description>
    </item>
    
    <item>
      <title>The Silent Rise of PyTorch Ecosystem</title>
      <link>https://nirantk.com/writing/silentriseofpytorch.html</link>
      <pubDate>Tue, 27 Aug 2019 23:29:18 +0530</pubDate>
      
      <guid>https://nirantk.com/writing/silentriseofpytorch.html</guid>
      <description>The Silent Rise of PyTorch Ecosystem While Tensorflow has made peace with Keras as it’s high level API and mxNet now support Gluon — PyTorch is the bare matrix love.
PyTorch has seen rapid adoption in academia and all the industrial labs that I have spoken to as well. One of the reasons people (specially engineers doing experiments) like PyTorch is the ease of debugging.
What I don’t like about PyTorch is it’s incessant requirement of debugging because of inconsistent dimensions problems.</description>
    </item>
    
    <item>
      <title>How to prepare for a Data Science job from college?</title>
      <link>https://nirantk.com/writing/datasciencejob.html</link>
      <pubDate>Mon, 12 Dec 2016 23:29:18 +0530</pubDate>
      
      <guid>https://nirantk.com/writing/datasciencejob.html</guid>
      <description>A Getting Started Guide
Let us get our facts straight, shall we?
I am writing from my non-existent but probably relevant experience. I worked in a Machine Learning role at Samsung Research, Bengaluru. It is only 1 of the 4 research enterprises which hire Machine Learning researchers from Indian colleges — the other being Microsoft, Xerox, and IBM Watson.
I am now in a even more Computer Vision focused role for a small enterprise tech company.</description>
    </item>
    
  </channel>
</rss>
